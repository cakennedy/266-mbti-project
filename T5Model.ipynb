{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR8V5tKRtX+4BgyFJUHnni",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cakennedy/266-mbti-project/blob/main/T5Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# W266 Final Project\n",
        "# Resampling\n",
        "# October 27, 2022\n",
        "# John Clark, Shrinivas Joshi, Courtney Kennedy\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cakennedy/266-mbti-project/blob/main/notebooks/T5Model.ipynb#)\n",
        "\n",
        "\n",
        "# Create a T5 Model and run it on our data"
      ],
      "metadata": {
        "id": "eY_-j1-r7FI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import io\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import altair as alt\n",
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn.utils import resample\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F00untZn7T2V",
        "outputId": "b645783a-48bc-44d5-cb97-4dbec08c3b04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration Flags\n",
        "\n",
        "useGCloudForStorage = True\n"
      ],
      "metadata": {
        "id": "cM4dA6Zr7Y16"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global State Flags\n",
        "uploadedGCloudCredentials = False\n",
        "mountedGoogleDrive = False\n",
        "configuredGCloud = False\n",
        "\n",
        "\n",
        "# Global Variables\n",
        "gdrive_path = '/content/drive/MyDrive/content/drive/'\n",
        "\n",
        "gcloud_bucket = None\n",
        "gcloud_bucket_name = \"\""
      ],
      "metadata": {
        "id": "JYhwPwXL7ZBF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To work from a google drive use this:\n",
        "from google.colab import drive\n",
        "\n",
        "def mount_google_drive():\n",
        "    global userGCloudForStorage\n",
        "    global mountedGoogleDrive\n",
        "\n",
        "    if useGCloudForStorage == False:\n",
        "        if mountedGoogleDrive == False:\n",
        "            drive.mount('/content/drive')\n",
        "            mountedGoogleDrive = True\n"
      ],
      "metadata": {
        "id": "PU-yR62h7ZIo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To work from gcloud, use this:\n",
        "\n",
        "# Upload Google Cloud service account key to enable authentication ( json file )\n",
        "# Go to https://console.cloud.google.com/:\n",
        "# Under the Navigation Menu ( upper left 3 horizontal lines) \n",
        "# 1. choose IAM & Admin>\n",
        "# 2. choose Service Accounts>\n",
        "# 3. Select a Service Account>\n",
        "# 4. Under the Actions menu ( 3 dots to the right of the service account )>Manage Keys to create your own json credentials file\n",
        "\n",
        "from google.colab import files\n",
        "from google.cloud import storage\n",
        "\n",
        "\n",
        "def upload_gcloud_credentials():\n",
        "    global useGCloudForStorage\n",
        "    global uploadedGCloudCredentials\n",
        "\n",
        "    if useGCloudForStorage:\n",
        "        if uploadedGCloudCredentials == False:\n",
        "\n",
        "            uploaded = files.upload()\n",
        "            uploadedGCloudCredentials = True\n",
        "\n",
        "\n",
        "def config_GCloud():\n",
        "    global configuredGCloud\n",
        "    global gcloud_bucket\n",
        "    global gcloud_bucket_name\n",
        "\n",
        "    if configuredGCloud:\n",
        "        return gcloud_bucket, gcloud_bucket_name\n",
        "\n",
        "    #Load Google Cloud storage client using service key\n",
        "    storage_client = storage.Client.from_service_account_json('pacific-castle-360400-a3ca89f64de6.json')\n",
        "    #Print buckets available\n",
        "    for bucket in storage_client.list_buckets():\n",
        "        print(bucket)\n",
        "\n",
        "    #Assign bucket name being used\n",
        "    gcloud_bucket_name = '266csffile'\n",
        "\n",
        "    #Get bucket\n",
        "    gcloud_bucket = storage_client.get_bucket(gcloud_bucket_name)\n",
        "\n",
        "    #Show list of files in bucket and list the files\n",
        "    filename = list(gcloud_bucket.list_blobs(prefix=''))\n",
        "    for name in filename:\n",
        "        print(name.name)\n",
        "\n",
        "    #Increase field size to allow reading in of files\n",
        "    maxInt = sys.maxsize\n",
        "\n",
        "    while True:\n",
        "        # decrease the maxInt value by factor 10 as long as overflow error occurs \n",
        "        try:\n",
        "            csv.field_size_limit(maxInt)\n",
        "            break\n",
        "        except OverflowError:\n",
        "            maxInt = int(maxInt/10)\n",
        "\n",
        "    configuredGCloud = True\n",
        "\n",
        "    return gcloud_bucket, gcloud_bucket_name\n"
      ],
      "metadata": {
        "id": "mcdoxC80-Eai"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write parquet files\n",
        "\n",
        "def write_parquet_google_cloud( df, filename):\n",
        "\n",
        "    bucket, bucket_name = config_GCloud()\n",
        "\n",
        "    blob = bucket.blob( filename )\n",
        "    blob.upload_from_string(df.to_parquet(), 'application/octet-stream')\n",
        "\n"
      ],
      "metadata": {
        "id": "3GcUvl1P-Ed3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_parquet_from_gcloud( filename ):\n",
        "\n",
        "    bucket, bucket_name = config_GCloud()\n",
        "\n",
        "    blob = bucket.blob( filename )\n",
        "    blob_string = blob.download_as_string()\n",
        "    \n",
        "    read_df = pd.read_parquet(io.BytesIO(blob_string))\n",
        "    return read_df\n"
      ],
      "metadata": {
        "id": "CIRqyb0n-TXS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upload_gcloud_credentials()\n",
        "bucket, bucket_name = config_GCloud()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n34mxVbX-EgN",
        "outputId": "c5700b7a-c3ee-4df5-f6de-7ec94a070658"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cda5eec2-3a6e-4aa1-8971-572265dcc602\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cda5eec2-3a6e-4aa1-8971-572265dcc602\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving pacific-castle-360400-a3ca89f64de6.json to pacific-castle-360400-a3ca89f64de6.json\n",
            "<Bucket: 266csffile>\n",
            "dev_is_I_data.parquet\n",
            "dev_is_I_labels.parquet\n",
            "dev_is_J_data.parquet\n",
            "dev_is_J_labels.parquet\n",
            "dev_is_S_data.parquet\n",
            "dev_is_S_labels.parquet\n",
            "dev_is_T_data.parquet\n",
            "dev_is_T_labels.parquet\n",
            "dev_mbti_data.parquet\n",
            "dev_mbti_labels.parquet\n",
            "old_files/\n",
            "old_files/dev_mbti_data.csv\n",
            "old_files/dev_mbti_data.parquet\n",
            "old_files/dev_mbti_labels.csv\n",
            "old_files/test_mbti_data.csv\n",
            "old_files/test_mbti_data.parquet\n",
            "old_files/test_mbti_labels.csv\n",
            "old_files/train_gen_pop_mbti_data.csv\n",
            "old_files/train_gen_pop_mbti_data.parquet\n",
            "old_files/train_gen_pop_mbti_labels.csv\n",
            "old_files/train_mbti_data.csv\n",
            "old_files/train_mbti_data.parquet\n",
            "old_files/train_mbti_labels.csv\n",
            "old_files/train_over_sampled_mbti_data.csv\n",
            "old_files/train_over_sampled_mbti_data.parquet\n",
            "old_files/train_over_sampled_mbti_labels.csv\n",
            "old_files/train_under_sampled_mbti_data.csv\n",
            "old_files/train_under_sampled_mbti_data.parquet\n",
            "old_files/train_under_sampled_mbti_labels.csv\n",
            "test_is_I_data.parquet\n",
            "test_is_I_labels.parquet\n",
            "test_is_J_data.parquet\n",
            "test_is_J_labels.parquet\n",
            "test_is_S_data.parquet\n",
            "test_is_S_labels.parquet\n",
            "test_is_T_data.parquet\n",
            "test_is_T_labels.parquet\n",
            "test_mbti_data.parquet\n",
            "test_mbti_labels.parquet\n",
            "train_gen_pop_is_I_data.parquet\n",
            "train_gen_pop_is_I_labels.parquet\n",
            "train_gen_pop_is_J_data.parquet\n",
            "train_gen_pop_is_J_labels.parquet\n",
            "train_gen_pop_is_S_data.parquet\n",
            "train_gen_pop_is_S_labels.parquet\n",
            "train_gen_pop_is_T_data.parquet\n",
            "train_gen_pop_is_T_labels.parquet\n",
            "train_gen_pop_mbti_data.parquet\n",
            "train_gen_pop_mbti_labels.parquet\n",
            "train_is_I_data.parquet\n",
            "train_is_I_labels.parquet\n",
            "train_is_J_data.parquet\n",
            "train_is_J_labels.parquet\n",
            "train_is_S_data.parquet\n",
            "train_is_S_labels.parquet\n",
            "train_is_T_data.parquet\n",
            "train_is_T_labels.parquet\n",
            "train_mbti_data.parquet\n",
            "train_mbti_labels.parquet\n",
            "train_uniform_is_I_data.parquet\n",
            "train_uniform_is_I_labels.parquet\n",
            "train_uniform_is_J_data.parquet\n",
            "train_uniform_is_J_labels.parquet\n",
            "train_uniform_is_S_data.parquet\n",
            "train_uniform_is_S_labels.parquet\n",
            "train_uniform_is_T_data.parquet\n",
            "train_uniform_is_T_labels.parquet\n",
            "train_uniform_mbti_data.parquet\n",
            "train_uniform_mbti_labels.parquet\n",
            "typology_merged.parquet\n",
            "typology_users_clean.csv\n",
            "typology_xenforo-9-25-22-posts.csv\n",
            "typology_xenforo-9-25-22.csv\n",
            "typology_xenforo-9-25-22_clean.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start with MBTI Training Data\n",
        "\n",
        "mbti_train_data_df = read_parquet_from_gcloud('train_mbti_data.parquet')\n",
        "mbti_train_labels_df  = read_parquet_from_gcloud('train_mbti_labels.parquet')\n",
        "\n",
        "mbti_train_uniform_data_df  = read_parquet_from_gcloud('train_uniform_mbti_data.parquet')\n",
        "mbti_train_uniform_labels_df  = read_parquet_from_gcloud('train_uniform_mbti_labels.parquet')\n",
        "\n",
        "\n",
        "mbti_train_genpop_data_df  = read_parquet_from_gcloud('train_gen_pop_mbti_data.parquet')\n",
        "mbti_train_genpop_labels_df  = read_parquet_from_gcloud('train_gen_pop_mbti_labels.parquet')"
      ],
      "metadata": {
        "id": "eER-NxfK-Eij"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Also get MBTI Dev and Test Data\n",
        "\n",
        "mbti_dev_data_df  = read_parquet_from_gcloud('dev_mbti_data.parquet')\n",
        "mbti_dev_labels_df  = read_parquet_from_gcloud('dev_mbti_labels.parquet')\n",
        "\n",
        "mbti_test_data_df  = read_parquet_from_gcloud('test_mbti_data.parquet')\n",
        "mbti_test_labels_df  = read_parquet_from_gcloud('test_mbti_labels.parquet')"
      ],
      "metadata": {
        "id": "AMjnH7AP-Emu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check the files\n",
        "\n",
        "df_dict = {}\n",
        "\n",
        "df_dict['train_data'] = mbti_train_data_df\n",
        "df_dict['train_labels'] = mbti_train_labels_df\n",
        "\n",
        "df_dict['train_uniform_data'] = mbti_train_uniform_data_df\n",
        "df_dict['train_uniform_labels'] = mbti_train_genpop_labels_df\n",
        "\n",
        "df_dict['train_genpop_data'] = mbti_train_genpop_data_df\n",
        "df_dict['train_genpop_labels'] = mbti_train_uniform_labels_df\n",
        "\n",
        "df_dict['dev_data'] = mbti_dev_data_df\n",
        "df_dict['dev_labels'] = mbti_dev_labels_df\n",
        "\n",
        "df_dict['test_data'] = mbti_test_data_df\n",
        "df_dict['test_labels'] = mbti_test_labels_df\n",
        "\n"
      ],
      "metadata": {
        "id": "6vq0BWN7AJ3-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for df in df_dict.values():\n",
        "    print( \"Shape:\", df.shape)\n",
        "    print( \"Columns:\", df.columns)\n",
        "    print( \"Head:\", df.head() )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8u12HzIBDlw",
        "outputId": "f63a907d-94f7-4ca9-9e9b-d7dba77742ad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (1200000, 16)\n",
            "Columns: Index(['original index', 'Username', 'Age', 'Posts', 'Enneagram',\n",
            "       'Instinctual Variant', 'Gender', 'Occupation', 'is_I', 'is_S', 'is_T',\n",
            "       'is_J', 'post_id', 'thread_id', 'post_date', 'message'],\n",
            "      dtype='object')\n",
            "Head:    original index      Username     Age  Posts Enneagram Instinctual Variant  \\\n",
            "0          275024      Coriolis    45.0  26905       5w6               sp_sx   \n",
            "1          913620    metaphours    42.0   1194       4w5                None   \n",
            "2          149964     Biaxident  2022.0   3617      None                None   \n",
            "3         1286867  Siúil a Rúin    51.0  13644       496               sx_sp   \n",
            "4          203249      Carebear    43.0   1449      None                None   \n",
            "\n",
            "          Gender                                     Occupation  is_I   is_S  \\\n",
            "0           male                                           None  True  False   \n",
            "1           None                                         living  True  False   \n",
            "2           None  Semi-pro curmudgeon/Stew-dent/ Full time INFP  True  False   \n",
            "3  not_specified       freelancing musician, aspiring counselor  True   True   \n",
            "4           None                                           None  True  False   \n",
            "\n",
            "    is_T   is_J  post_id  thread_id   post_date  \\\n",
            "0   True   True  2030493      60459  1359485858   \n",
            "1  False  False   780620      20355  1249966500   \n",
            "2  False  False   846124      22243  1254074326   \n",
            "3  False  False   259987       7052  1187976158   \n",
            "4  False  False   188880        558  1207903155   \n",
            "\n",
            "                                             message  \n",
            "0  xntj, though eYYY would tend to go more with X...  \n",
            "1    architecture can carry so much weight, canno...  \n",
            "2    well, if google is correct than us XXXXs hav...  \n",
            "3    knowing that the situation is complex, i hes...  \n",
            "4    :d  somehow the effort seemed so much more s...  \n",
            "Shape: (1200000, 2)\n",
            "Columns: Index(['original index', 'MBTI Type'], dtype='object')\n",
            "Head:    original index MBTI Type\n",
            "0          275024      INTJ\n",
            "1          913620      INFP\n",
            "2          149964      INFP\n",
            "3         1286867      ISFP\n",
            "4          203249      INFP\n",
            "Shape: (1200000, 17)\n",
            "Columns: Index(['index', 'original index', 'Username', 'Age', 'Posts', 'Enneagram',\n",
            "       'Instinctual Variant', 'Gender', 'Occupation', 'is_I', 'is_S', 'is_T',\n",
            "       'is_J', 'post_id', 'thread_id', 'post_date', 'message'],\n",
            "      dtype='object')\n",
            "Head:      index  original index        Username   Age  Posts Enneagram  \\\n",
            "0   172921          239514          chegra  38.0    132      None   \n",
            "1   414795         1386730           Taito  32.0   5965       368   \n",
            "2   862504         1063932  PumpkinMayCare  29.0   1078       714   \n",
            "3  1095937          127714     Azure Flame  34.0   2317       8w7   \n",
            "4    50338         1385747           Taito  32.0   5965       368   \n",
            "\n",
            "  Instinctual Variant         Gender Occupation   is_I   is_S   is_T   is_J  \\\n",
            "0                None           None       None   True  False  False   True   \n",
            "1               sp_sx  not_specified       None   True   True   True  False   \n",
            "2               so_sp         female       None  False  False  False  False   \n",
            "3                None           None       None  False   True   True  False   \n",
            "4               sp_sx  not_specified       None   True   True   True  False   \n",
            "\n",
            "   post_id  thread_id   post_date  \\\n",
            "0   585756      14899  1237813215   \n",
            "1  3246405      17957  1597163164   \n",
            "2  3005688        441  1526590721   \n",
            "3  2094783      63037  1371407136   \n",
            "4  3207587     104250  1583440187   \n",
            "\n",
            "                                             message  \n",
            "0  wow XXXX has a fan base nice.  i do not know h...  \n",
            "1  i am friends with some people whose belief sys...  \n",
            "2    what do you mean by \"limit the number of pos...  \n",
            "3  i thought hopkins was good at first, but trend...  \n",
            "4    gangs of liberals are kind of fun though, th...  \n",
            "Shape: (1199999, 2)\n",
            "Columns: Index(['original index', 'MBTI Type'], dtype='object')\n",
            "Head:    original index MBTI Type\n",
            "0          549940      ISFP\n",
            "1         1065723      ESFJ\n",
            "2          231860      ENTP\n",
            "3         1412336      ISFP\n",
            "4         1254851      ESFJ\n",
            "Shape: (1199999, 17)\n",
            "Columns: Index(['index', 'original index', 'Username', 'Age', 'Posts', 'Enneagram',\n",
            "       'Instinctual Variant', 'Gender', 'Occupation', 'is_I', 'is_S', 'is_T',\n",
            "       'is_J', 'post_id', 'thread_id', 'post_date', 'message'],\n",
            "      dtype='object')\n",
            "Head:      index  original index      Username   Age  Posts Enneagram  \\\n",
            "0  1005117          549940  GoggleGirl17  29.0    472       479   \n",
            "1  1154593         1065723  pure_mercury  40.0   6946      None   \n",
            "2   461466          231860      Cenomite  34.0    623      None   \n",
            "3    16924         1412336      Thalassa  45.0  25183       6w7   \n",
            "4    87377         1254851     Showbread  29.0   2298       3w2   \n",
            "\n",
            "  Instinctual Variant         Gender  \\\n",
            "0               sp_sx         female   \n",
            "1                None           None   \n",
            "2                None           None   \n",
            "3                  sx  not_specified   \n",
            "4               so_sp         female   \n",
            "\n",
            "                                          Occupation   is_I   is_S   is_T  \\\n",
            "0                                               None   True   True  False   \n",
            "1               film major/Medical Records Assistant  False   True  False   \n",
            "2                                               None  False  False   True   \n",
            "3                                        Tree people   True   True  False   \n",
            "4  Mentoring college students, being a dog mom, a...  False   True  False   \n",
            "\n",
            "    is_J  post_id  thread_id   post_date  \\\n",
            "0  False  3314576     109526  1615322971   \n",
            "1   True   207872       5630  1210648898   \n",
            "2  False   799238      20885  1251052291   \n",
            "3  False   961858      10883  1260750656   \n",
            "4   True  2531892      70854  1443213165   \n",
            "\n",
            "                                             message  \n",
            "0  this is more of a theme song than something th...  \n",
            "1    everything i have ever read or heard secondh...  \n",
            "2  kangirl, if you get the whip, i will get my le...  \n",
            "3                  and damn does it feel good.  jk..  \n",
            "4  oh sorry i guess i was suppose to ask you to m...  \n",
            "Shape: (1200000, 2)\n",
            "Columns: Index(['original index', 'MBTI Type'], dtype='object')\n",
            "Head:    original index MBTI Type\n",
            "0          239514      INFJ\n",
            "1         1386730      ISTP\n",
            "2         1063932      ENFP\n",
            "3          127714      ESTP\n",
            "4         1385747      ISTP\n",
            "Shape: (200000, 16)\n",
            "Columns: Index(['original index', 'Username', 'Age', 'Posts', 'Enneagram',\n",
            "       'Instinctual Variant', 'Gender', 'Occupation', 'is_I', 'is_S', 'is_T',\n",
            "       'is_J', 'post_id', 'thread_id', 'post_date', 'message'],\n",
            "      dtype='object')\n",
            "Head:          original index        Username   Age  Posts Enneagram  \\\n",
            "1200000          225208          ceecee  54.0  15108       8w9   \n",
            "1200001         1279120  simulatedworld  35.0   5552       7w6   \n",
            "1200002          355178             EcK  36.0   7705       738   \n",
            "1200003          779566          Kasper  42.0  11590       9w8   \n",
            "1200004         1112817    RaptorWizard  28.0   5903       5w6   \n",
            "\n",
            "        Instinctual Variant         Gender  \\\n",
            "1200000                None  not_specified   \n",
            "1200001               sx_so           male   \n",
            "1200002                None           male   \n",
            "1200003               so_sx           male   \n",
            "1200004               sx_so           None   \n",
            "\n",
            "                                                Occupation   is_I   is_S  \\\n",
            "1200000                                               None   True  False   \n",
            "1200001  Private music teacher (guitar, bass, voice, pi...  False  False   \n",
            "1200002                                                yes  False  False   \n",
            "1200003                                               None  False  False   \n",
            "1200004                                      Worldbuilding   True  False   \n",
            "\n",
            "         is_T   is_J  post_id  thread_id   post_date  \\\n",
            "1200000  True   True  2938197      93650  1514840302   \n",
            "1200001  True  False   753655      19602  1248456008   \n",
            "1200002  True  False   898180      15681  1257053828   \n",
            "1200003  True  False   608781      15681  1239316541   \n",
            "1200004  True   True  2010969      57152  1355789312   \n",
            "\n",
            "                                                   message  \n",
            "1200000            [mediayoutube]YYYvynasYYYqYYYsg[/media]  \n",
            "1200001  ^ oh well, if you say so.  i have seen him tal...  \n",
            "1200002    udog, stop throwing yourself at me already :...  \n",
            "1200003          dear silent,  i adore you :wub:  YYY trin  \n",
            "1200004    lol that reminds me of this episode of curb ...  \n",
            "Shape: (200000, 2)\n",
            "Columns: Index(['original index', 'MBTI Type'], dtype='object')\n",
            "Head:          original index MBTI Type\n",
            "1200000          225208      INTJ\n",
            "1200001         1279120      ENTP\n",
            "1200002          355178      ENTP\n",
            "1200003          779566      ENTP\n",
            "1200004         1112817      INTJ\n",
            "Shape: (200000, 16)\n",
            "Columns: Index(['original index', 'Username', 'Age', 'Posts', 'Enneagram',\n",
            "       'Instinctual Variant', 'Gender', 'Occupation', 'is_I', 'is_S', 'is_T',\n",
            "       'is_J', 'post_id', 'thread_id', 'post_date', 'message'],\n",
            "      dtype='object')\n",
            "Head:          original index       Username   Age  Posts Enneagram  \\\n",
            "1400000          110045    Athenian200  34.0   8828       4w5   \n",
            "1400001          107821    Athenian200  34.0   8828       4w5   \n",
            "1400002          865471  Littleclaypot  34.0    629       297   \n",
            "1400003          354073            EcK  36.0   7705       738   \n",
            "1400004         1412046       Thalassa  45.0  25183       6w7   \n",
            "\n",
            "        Instinctual Variant         Gender        Occupation   is_I   is_S  \\\n",
            "1400000                None           None              None   True  False   \n",
            "1400001                None           None              None   True  False   \n",
            "1400002               so_sx         female  history teacher.   True  False   \n",
            "1400003                None           male               yes  False  False   \n",
            "1400004                  sx  not_specified       Tree people   True   True   \n",
            "\n",
            "          is_T   is_J  post_id  thread_id   post_date  \\\n",
            "1400000  False   True   765561      19952  1249167121   \n",
            "1400001  False   True   531272      13707  1233914270   \n",
            "1400002  False   True  2859189        622  1498744326   \n",
            "1400003   True  False   564920      14551  1236206658   \n",
            "1400004  False  False   950458      25029  1260164679   \n",
            "\n",
            "                                                   message  \n",
            "1400000  yeah, epp, we definitely sound similar on ever...  \n",
            "1400001    i have said it before, and i will say it aga...  \n",
            "1400002    to the bolded, i think that is probably true...  \n",
            "1400003  this was \" a day in the shoes of a crazy perso...  \n",
            "1400004                  been watching bathurst videos..    \n",
            "Shape: (200000, 2)\n",
            "Columns: Index(['original index', 'MBTI Type'], dtype='object')\n",
            "Head:          original index MBTI Type\n",
            "1400000          110045      INFJ\n",
            "1400001          107821      INFJ\n",
            "1400002          865471      INFJ\n",
            "1400003          354073      ENTP\n",
            "1400004         1412046      ISFP\n"
          ]
        }
      ]
    }
  ]
}